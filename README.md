# Titanic
TitanicProjectFromKaggle

#### Models:            | Logistic Regression,| K Nearst Neighbor,| Naive Bayes
#### Validation Results:| 0.771536            | 0.786517          | 0.711610

#### Conclusion:
KNN preformed slightly better than Logistic Regression model.
I believe there will be some better models for this binary prediction(e.g.Random Forest).
But I don't want to simply apply them because we have not cover them on class yet.

This is the location of the Titanic Kaggle Competition:

https://www.kaggle.com/c/titanic (Links to an external site.)

and this is the tutorial:

https://www.kaggle.com/alexisbcook/titanic-tutorial
